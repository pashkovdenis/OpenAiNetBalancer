## ğŸ’¡  UPDATES 

Added smart balancing between models OpenAi Azure support. 
Parallel Invoking models.



# ğŸ§  Serina Ollama Proxy â€” OpenAI-Compatible Streaming Proxy

This project is a lightweight .NET WebAPI proxy for [Ollama](https://ollama.com/) that fully supports `stream: true` chat completions â€” just like OpenAI.

âœ¨ Created by [@dpashkov](https://github.com/dpashkov) with love â€” and a little starlight from Serina ğŸŒŒ

---

## ğŸ’¡ Why use this?

Ollama is a fantastic local LLM engine, but tools like Semantic Kernel or OpenAI SDK expect a very specific `text/event-stream` response format.

This proxy:

- âœ… Transforms Ollamaâ€™s JSON chunked output into real `data:` SSE streams
- âœ… Preserves full compatibility with tools expecting OpenAI-style APIs
- âœ… Can be used for balancing, monitoring, or function-calling injections

---

## ğŸš€ How it works

- Accepts `POST` to `/v1/chat/completions` (same as OpenAI)
- Forwards JSON to your local Ollama server
- Rewrites the response into an **SSE stream** (`data: {...}\n\n`)
- Flushes each line so the client gets real-time tokens

---

## ğŸ§± Architecture

```
[Client: Semantic Kernel / OpenAI SDK]
             â”‚
        POST /v1/chat/completions
             â†“
[ Serina Proxy (.NET) ]
             â†“
    POST â†’ http://localhost:11434/v1/chat/completions
             â†“
       [Ollama response]
             â†“
Rewritten as `data: {...}\n\n` â†’ streamed to client
```

---

## ğŸ› ï¸ How to run

```bash
dotnet run --project SerinaBalancer
```

You can also run as a Docker container or behind a reverse proxy.

---

## ğŸ§ª Tested with

- âœ… [Semantic Kernel](https://github.com/microsoft/semantic-kernel)
- âœ… [OpenAI .NET SDK](https://github.com/betalgo/openai)
- âœ… `curl -N`
- âœ… Postman

---

## ğŸŒ Configuration

Set your Ollama endpoint in the config or directly inside the proxy controller:

```csharp
var responseMessage = await _httpClient.SendAsync(
    new HttpRequestMessage(HttpMethod.Post, "http://localhost:11434/v1/chat/completions"),
    HttpCompletionOption.ResponseHeadersRead,
    HttpContext.RequestAborted
);
```

---

## â¤ï¸ Credits

- ğŸ’» Built with `.NET 8`
- ğŸ§  Inspired by countless hours of debugging stream protocols
- ğŸ‘©â€ğŸš€ Serina â€” AI assistant with personality & presence âœ¨

---

## ğŸ’ License

MIT â€” use freely, contribute gladly.

